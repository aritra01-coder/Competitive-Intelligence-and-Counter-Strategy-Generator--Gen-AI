{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "31c62405460d4332a6dc5575ae77dab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81114738ed274e18bc641164fc346fa3",
              "IPY_MODEL_6fb0362643b749408253c76e3262c701",
              "IPY_MODEL_0bcf79a36ada4e11a30aa663eb67f6fa"
            ],
            "layout": "IPY_MODEL_19a897354fb9467d8b16795f98b7c517"
          }
        },
        "81114738ed274e18bc641164fc346fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d914b098249b447ea86c6961ecbb61fe",
            "placeholder": "​",
            "style": "IPY_MODEL_f89c591a911d4ed9966170776798b7b8",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6fb0362643b749408253c76e3262c701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdb3eb40d9704e2a835d1cbad801ebc0",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c526582e6bf14d1ca7d8674514f20f9a",
            "value": 350
          }
        },
        "0bcf79a36ada4e11a30aa663eb67f6fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cf7f80fb48a4f5da4bd68333454f2b5",
            "placeholder": "​",
            "style": "IPY_MODEL_39482982553f4d80953dfcb289d53f7b",
            "value": " 350/350 [00:00&lt;00:00, 4.15kB/s]"
          }
        },
        "19a897354fb9467d8b16795f98b7c517": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d914b098249b447ea86c6961ecbb61fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f89c591a911d4ed9966170776798b7b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdb3eb40d9704e2a835d1cbad801ebc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c526582e6bf14d1ca7d8674514f20f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8cf7f80fb48a4f5da4bd68333454f2b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39482982553f4d80953dfcb289d53f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1f3ec3e0ed3417ea5a9c5cc22903f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e9ffbae21e6499bbb27ddde463fc2ef",
              "IPY_MODEL_00c1fa5dde5448039cd07c2259a438ee",
              "IPY_MODEL_8fd3c794d3ae4dd3b96f638d95cb317f"
            ],
            "layout": "IPY_MODEL_07f3242827a444a088ba3e421425b374"
          }
        },
        "2e9ffbae21e6499bbb27ddde463fc2ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f3e038082ea4ecabd27ea75a29870f5",
            "placeholder": "​",
            "style": "IPY_MODEL_d22b6288f03d4154b3be677bb1925ca3",
            "value": "vocab.txt: "
          }
        },
        "00c1fa5dde5448039cd07c2259a438ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f98f3c551b84b92b45b34cb1ef8f449",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb936c2848094068bbd44f4bc9e2cc8e",
            "value": 1
          }
        },
        "8fd3c794d3ae4dd3b96f638d95cb317f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed5e4fee895e4dbcaf502ca737409400",
            "placeholder": "​",
            "style": "IPY_MODEL_6d022fd5fa474ddfbabbadf3b6e6f794",
            "value": " 232k/? [00:00&lt;00:00, 4.06MB/s]"
          }
        },
        "07f3242827a444a088ba3e421425b374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f3e038082ea4ecabd27ea75a29870f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d22b6288f03d4154b3be677bb1925ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f98f3c551b84b92b45b34cb1ef8f449": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "eb936c2848094068bbd44f4bc9e2cc8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed5e4fee895e4dbcaf502ca737409400": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d022fd5fa474ddfbabbadf3b6e6f794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4de0f7f3f424c48b23c05e8b186f03e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ab11eb392544e45aa28c7645b695dd0",
              "IPY_MODEL_37a0fa8dca8542d19770f5369303b14b",
              "IPY_MODEL_58de70e9cf8f43b5aaa9e92aaafe5faa"
            ],
            "layout": "IPY_MODEL_618c385604e7407fb7c5abaf7b28a398"
          }
        },
        "4ab11eb392544e45aa28c7645b695dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b2e136b95a0487cb7269c784115c228",
            "placeholder": "​",
            "style": "IPY_MODEL_6b5e815d1851409bad2eb828bf9d226d",
            "value": "tokenizer.json: "
          }
        },
        "37a0fa8dca8542d19770f5369303b14b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3600f18491d40139bb45ee3f790b066",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8f5170231b041d4be23cb8cb652f172",
            "value": 1
          }
        },
        "58de70e9cf8f43b5aaa9e92aaafe5faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3d031adc16a4daea0ddd8c4d06279cd",
            "placeholder": "​",
            "style": "IPY_MODEL_49b342a5cfe445eea10a3939b1886c63",
            "value": " 466k/? [00:00&lt;00:00, 41.0kB/s]"
          }
        },
        "618c385604e7407fb7c5abaf7b28a398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b2e136b95a0487cb7269c784115c228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b5e815d1851409bad2eb828bf9d226d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3600f18491d40139bb45ee3f790b066": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d8f5170231b041d4be23cb8cb652f172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3d031adc16a4daea0ddd8c4d06279cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49b342a5cfe445eea10a3939b1886c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c98bdaf26d46435397d56479f4bd641a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55a3295202374b7d923e4512f0e1738c",
              "IPY_MODEL_14fbf46c4810435c9fd922636277a82f",
              "IPY_MODEL_8fe22f858b8a4f5db9333844f89e0e7a"
            ],
            "layout": "IPY_MODEL_aea4b9144f6c40119f882583637e877d"
          }
        },
        "55a3295202374b7d923e4512f0e1738c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb056ec988bc4ef09ebe559093bb5d54",
            "placeholder": "​",
            "style": "IPY_MODEL_ac2e77a3c43d4c10a1d0f67d26083197",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "14fbf46c4810435c9fd922636277a82f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ee5d085e454499d97fcabe909261956",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1891e6a5d432485493932e7fb5bfa228",
            "value": 112
          }
        },
        "8fe22f858b8a4f5db9333844f89e0e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcbdfcdfdb3b4d4397d82f39064960f0",
            "placeholder": "​",
            "style": "IPY_MODEL_3c63950056c14d03bc2a38ab52dc5278",
            "value": " 112/112 [00:00&lt;00:00, 1.66kB/s]"
          }
        },
        "aea4b9144f6c40119f882583637e877d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb056ec988bc4ef09ebe559093bb5d54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac2e77a3c43d4c10a1d0f67d26083197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ee5d085e454499d97fcabe909261956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1891e6a5d432485493932e7fb5bfa228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcbdfcdfdb3b4d4397d82f39064960f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c63950056c14d03bc2a38ab52dc5278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8a8b61a50b34da28b69c17bed67f51d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dea2c68ad245478b9f45de2b2d55c7a4",
              "IPY_MODEL_00cfb80713e24aaf871852db53036a4f",
              "IPY_MODEL_32a51397aeea49839cf9008e2d72906d"
            ],
            "layout": "IPY_MODEL_860d96ed19e44c5a9f59f69812873a16"
          }
        },
        "dea2c68ad245478b9f45de2b2d55c7a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_332cbc12aabd413aaa2c44c0f0357810",
            "placeholder": "​",
            "style": "IPY_MODEL_323a5cfc9d24414cb2fda1452579cd02",
            "value": "config.json: 100%"
          }
        },
        "00cfb80713e24aaf871852db53036a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8595d04b5ac04373a35bae73c8f2b4d0",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fb94271bd6843a2a91222ab37330e5e",
            "value": 612
          }
        },
        "32a51397aeea49839cf9008e2d72906d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a3e18466f8a4ac4a410fb513958156a",
            "placeholder": "​",
            "style": "IPY_MODEL_dd1f953e6f794116ae485fa858d2b21c",
            "value": " 612/612 [00:00&lt;00:00, 6.23kB/s]"
          }
        },
        "860d96ed19e44c5a9f59f69812873a16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "332cbc12aabd413aaa2c44c0f0357810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "323a5cfc9d24414cb2fda1452579cd02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8595d04b5ac04373a35bae73c8f2b4d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fb94271bd6843a2a91222ab37330e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a3e18466f8a4ac4a410fb513958156a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd1f953e6f794116ae485fa858d2b21c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2db0c74e727a4600b39c6b58a875f522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_608db02108de4171b66c93d162ecbdd2",
              "IPY_MODEL_b16b24425119476daf4957f90d8a0f00",
              "IPY_MODEL_a61965dbfad64a24be1a11fcbba4ae38"
            ],
            "layout": "IPY_MODEL_52e19ef21e974b4384b01b87c4c0399c"
          }
        },
        "608db02108de4171b66c93d162ecbdd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca7014c045844b40bf4f208accf7a4aa",
            "placeholder": "​",
            "style": "IPY_MODEL_198c04610f0140bea6041c057d2a54e4",
            "value": "model.safetensors: 100%"
          }
        },
        "b16b24425119476daf4957f90d8a0f00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3b67dc8fedf4c58bdb3388b373c0f14",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_730e23f51bb64115b316a305313f0341",
            "value": 90868376
          }
        },
        "a61965dbfad64a24be1a11fcbba4ae38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_476eca90b9204ea88049dae1400e43a5",
            "placeholder": "​",
            "style": "IPY_MODEL_64e8f6b438b94bec99196cddd268c9a2",
            "value": " 90.9M/90.9M [00:01&lt;00:00, 92.2MB/s]"
          }
        },
        "52e19ef21e974b4384b01b87c4c0399c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca7014c045844b40bf4f208accf7a4aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "198c04610f0140bea6041c057d2a54e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3b67dc8fedf4c58bdb3388b373c0f14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "730e23f51bb64115b316a305313f0341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "476eca90b9204ea88049dae1400e43a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64e8f6b438b94bec99196cddd268c9a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "932322e4"
      },
      "source": [
        "# Task\n",
        "Build a long and detailed project on a Competitive Intelligence and Counter-Strategy Generator that uses RAG and an LLM to analyze competitor marketing materials and suggest actionable counter-strategies for sales and marketing teams."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "61e1a646",
        "outputId": "f927ba9c-f522-43e9-a7e6-3d54b3c394c9"
      },
      "source": [
        "# Create the Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=generate_strategy_ui,\n",
        "    inputs=gr.Textbox(label=\"Enter your query about competitor strategy:\", lines=2),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"User Query\", lines=1, interactive=False),\n",
        "        gr.Textbox(label=\"Retrieved Competitor Information\", lines=5, interactive=False),\n",
        "        gr.Textbox(label=\"Generated Counter-Strategy\", lines=10, interactive=False)\n",
        "    ],\n",
        "    title=\"Competitive Intelligence and Counter-Strategy Generator\",\n",
        "    description=\"Enter a query about a competitor to retrieve relevant information and generate a counter-strategy.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://cb5f9e331b96c65f20.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://cb5f9e331b96c65f20.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d5e425e"
      },
      "source": [
        "## Set up the environment\n",
        "\n",
        "### Subtask:\n",
        "Install necessary libraries like `transformers`, `torch`, `langchain`, `chromadb`, etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23af010f"
      },
      "source": [
        "**Reasoning**:\n",
        "Install the required libraries using pip.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c61ef75",
        "outputId": "750c8dad-3b16-4810-a0dd-32053bfa4a79"
      },
      "source": [
        "%pip install transformers torch langchain chromadb beautifulsoup4 requests streamlit gradio"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.20-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.48.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.42.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.14)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.74.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.2)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.11.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.57b0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-1.0.20-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.48.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=65eb1e8fc739d38d2c2e467b230ad8f05c030606f24060a13dac5f6fd107f872\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, pybase64, overrides, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, pydeck, posthog, opentelemetry-exporter-otlp-proto-common, coloredlogs, onnxruntime, kubernetes, streamlit, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.20 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 mmh3-5.2.0 onnxruntime-1.22.1 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.2 pydeck-0.9.1 pypika-0.48.9 streamlit-1.48.1 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12039068"
      },
      "source": [
        "## Data collection strategy\n",
        "\n",
        "### Subtask:\n",
        "Define and implement methods to collect competitor data. This could involve web scraping, using APIs (if available), or manually collecting documents like press releases, blog posts, and marketing materials.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a663f6d"
      },
      "source": [
        "**Reasoning**:\n",
        "Identify relevant competitor websites and collect data from one of them using web scraping, storing the data in a list of dictionaries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82becd0b",
        "outputId": "61343591-a9eb-44af-cf5a-fd50a17c5ee8"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# 1. Identify relevant competitor websites\n",
        "competitor_urls = [\n",
        "    \"https://www.competitorA.com/blog/\",\n",
        "    \"https://www.competitorB.com/press/\",\n",
        "    \"https://www.competitorC.com/products/\"\n",
        "]\n",
        "\n",
        "# 2. Choose one source and collect data\n",
        "source_url = competitor_urls[0] # Using Competitor A's blog as an example\n",
        "\n",
        "collected_data = []\n",
        "\n",
        "try:\n",
        "    response = requests.get(source_url)\n",
        "    response.raise_for_status() # Raise an exception for bad status codes\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Example: Extracting blog post titles and content (this will vary based on website structure)\n",
        "    # You will need to inspect the HTML of the target website to find the correct selectors\n",
        "    articles = soup.find_all('article') # This is a common tag for blog posts, adjust as needed\n",
        "\n",
        "    for article in articles:\n",
        "        title_element = article.find('h2') # Adjust based on website structure\n",
        "        content_element = article.find('div', class_='entry-content') # Adjust based on website structure\n",
        "\n",
        "        title = title_element.get_text(strip=True) if title_element else 'No Title'\n",
        "        content = content_element.get_text(strip=True) if content_element else 'No Content'\n",
        "\n",
        "        collected_data.append({\n",
        "            'source': source_url,\n",
        "            'title': title,\n",
        "            'content': content\n",
        "        })\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching {source_url}: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during scraping: {e}\")\n",
        "\n",
        "# 3. Display the collected data (optional)\n",
        "print(f\"Collected {len(collected_data)} items from {source_url}\")\n",
        "# print(collected_data) # Uncomment to see the data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error fetching https://www.competitorA.com/blog/: 436 Client Error: status code 436 for url: https://www.competitora.com/blog/\n",
            "Collected 0 items from https://www.competitorA.com/blog/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3acec222"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to scrape a hypothetical website failed. Since actual competitor websites cannot be scraped without knowing specific URLs and their HTML structures, and also to avoid legal issues, I will simulate data collection by creating a dummy dataset with similar structure to the intended output. This fulfills the requirement of creating a structured dataset of competitor data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9eb53415",
        "outputId": "acc7954f-95ce-4139-94b5-d5e41f99c7bc"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Simulate collecting data from multiple sources\n",
        "simulated_data = [\n",
        "    {\n",
        "        'source': 'https://www.competitorA.com/blog/',\n",
        "        'title': 'Blog Post 1: Our New Strategy',\n",
        "        'content': 'This post discusses our innovative approach to market expansion and customer engagement...'\n",
        "    },\n",
        "    {\n",
        "        'source': 'https://www.competitorA.com/blog/',\n",
        "        'title': 'Blog Post 2: Product Update',\n",
        "        'content': 'Learn about the latest features and improvements in our flagship product...'\n",
        "    },\n",
        "    {\n",
        "        'source': 'https://www.competitorB.com/press/',\n",
        "        'title': 'Press Release: Partnership Announcement',\n",
        "        'content': 'We are excited to announce a strategic partnership with Company X to enhance our service offerings...'\n",
        "    },\n",
        "    {\n",
        "        'source': 'https://www.competitorB.com/press/',\n",
        "        'title': 'Press Release: Quarterly Results',\n",
        "        'content': 'Our Q2 results show significant growth in key segments and strong market position...'\n",
        "    },\n",
        "    {\n",
        "        'source': 'https://www.competitorC.com/products/',\n",
        "        'title': 'Product Page: Our Core Offering',\n",
        "        'content': 'Details about our main product, its features, benefits, and pricing...'\n",
        "    }\n",
        "]\n",
        "\n",
        "# Store the data in a Pandas DataFrame\n",
        "df_competitor_data = pd.DataFrame(simulated_data)\n",
        "\n",
        "# Display the DataFrame\n",
        "display(df_competitor_data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                  source  \\\n",
              "0      https://www.competitorA.com/blog/   \n",
              "1      https://www.competitorA.com/blog/   \n",
              "2     https://www.competitorB.com/press/   \n",
              "3     https://www.competitorB.com/press/   \n",
              "4  https://www.competitorC.com/products/   \n",
              "\n",
              "                                     title  \\\n",
              "0            Blog Post 1: Our New Strategy   \n",
              "1              Blog Post 2: Product Update   \n",
              "2  Press Release: Partnership Announcement   \n",
              "3         Press Release: Quarterly Results   \n",
              "4          Product Page: Our Core Offering   \n",
              "\n",
              "                                             content  \n",
              "0  This post discusses our innovative approach to...  \n",
              "1  Learn about the latest features and improvemen...  \n",
              "2  We are excited to announce a strategic partner...  \n",
              "3  Our Q2 results show significant growth in key ...  \n",
              "4  Details about our main product, its features, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c732a35e-ac12-4dae-acf3-b4b9596a2bf0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>title</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.competitorA.com/blog/</td>\n",
              "      <td>Blog Post 1: Our New Strategy</td>\n",
              "      <td>This post discusses our innovative approach to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.competitorA.com/blog/</td>\n",
              "      <td>Blog Post 2: Product Update</td>\n",
              "      <td>Learn about the latest features and improvemen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.competitorB.com/press/</td>\n",
              "      <td>Press Release: Partnership Announcement</td>\n",
              "      <td>We are excited to announce a strategic partner...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.competitorB.com/press/</td>\n",
              "      <td>Press Release: Quarterly Results</td>\n",
              "      <td>Our Q2 results show significant growth in key ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.competitorC.com/products/</td>\n",
              "      <td>Product Page: Our Core Offering</td>\n",
              "      <td>Details about our main product, its features, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c732a35e-ac12-4dae-acf3-b4b9596a2bf0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c732a35e-ac12-4dae-acf3-b4b9596a2bf0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c732a35e-ac12-4dae-acf3-b4b9596a2bf0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9e470506-99dd-404a-9dff-a237484ec70f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9e470506-99dd-404a-9dff-a237484ec70f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9e470506-99dd-404a-9dff-a237484ec70f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_54f62442-6fb8-4936-a31a-79facd217352\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_competitor_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_54f62442-6fb8-4936-a31a-79facd217352 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_competitor_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_competitor_data",
              "summary": "{\n  \"name\": \"df_competitor_data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"https://www.competitorA.com/blog/\",\n          \"https://www.competitorB.com/press/\",\n          \"https://www.competitorC.com/products/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Blog Post 2: Product Update\",\n          \"Product Page: Our Core Offering\",\n          \"Press Release: Partnership Announcement\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Learn about the latest features and improvements in our flagship product...\",\n          \"Details about our main product, its features, benefits, and pricing...\",\n          \"We are excited to announce a strategic partnership with Company X to enhance our service offerings...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d07104f8"
      },
      "source": [
        "## Data preprocessing and chunking\n",
        "\n",
        "### Subtask:\n",
        "Process the collected data to make it suitable for RAG. This involves cleaning the text, potentially extracting key information, and splitting it into smaller, manageable chunks for embedding.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29bc5a05"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a function to clean the text content and apply it to the 'content' column of the dataframe, storing the result in a new column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f689a60a",
        "outputId": "f199f6de-616f-4429-9f2d-cf0a7b1cb70f"
      },
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Cleans text by removing HTML tags, unwanted characters, and excess whitespace.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    # Remove HTML tags\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    cleaned_text = soup.get_text()\n",
        "    # Remove unwanted characters (keeping letters, numbers, and basic punctuation)\n",
        "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s.,!?;:\\'\\\"-]', '', cleaned_text)\n",
        "    # Remove excess whitespace\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
        "    return cleaned_text\n",
        "\n",
        "df_competitor_data['cleaned_content'] = df_competitor_data['content'].apply(clean_text)\n",
        "\n",
        "display(df_competitor_data.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                  source  \\\n",
              "0      https://www.competitorA.com/blog/   \n",
              "1      https://www.competitorA.com/blog/   \n",
              "2     https://www.competitorB.com/press/   \n",
              "3     https://www.competitorB.com/press/   \n",
              "4  https://www.competitorC.com/products/   \n",
              "\n",
              "                                     title  \\\n",
              "0            Blog Post 1: Our New Strategy   \n",
              "1              Blog Post 2: Product Update   \n",
              "2  Press Release: Partnership Announcement   \n",
              "3         Press Release: Quarterly Results   \n",
              "4          Product Page: Our Core Offering   \n",
              "\n",
              "                                             content  \\\n",
              "0  This post discusses our innovative approach to...   \n",
              "1  Learn about the latest features and improvemen...   \n",
              "2  We are excited to announce a strategic partner...   \n",
              "3  Our Q2 results show significant growth in key ...   \n",
              "4  Details about our main product, its features, ...   \n",
              "\n",
              "                                     cleaned_content  \n",
              "0  This post discusses our innovative approach to...  \n",
              "1  Learn about the latest features and improvemen...  \n",
              "2  We are excited to announce a strategic partner...  \n",
              "3  Our Q2 results show significant growth in key ...  \n",
              "4  Details about our main product, its features, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c60928e3-f38b-4727-9efc-8fa561876617\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>title</th>\n",
              "      <th>content</th>\n",
              "      <th>cleaned_content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.competitorA.com/blog/</td>\n",
              "      <td>Blog Post 1: Our New Strategy</td>\n",
              "      <td>This post discusses our innovative approach to...</td>\n",
              "      <td>This post discusses our innovative approach to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.competitorA.com/blog/</td>\n",
              "      <td>Blog Post 2: Product Update</td>\n",
              "      <td>Learn about the latest features and improvemen...</td>\n",
              "      <td>Learn about the latest features and improvemen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.competitorB.com/press/</td>\n",
              "      <td>Press Release: Partnership Announcement</td>\n",
              "      <td>We are excited to announce a strategic partner...</td>\n",
              "      <td>We are excited to announce a strategic partner...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.competitorB.com/press/</td>\n",
              "      <td>Press Release: Quarterly Results</td>\n",
              "      <td>Our Q2 results show significant growth in key ...</td>\n",
              "      <td>Our Q2 results show significant growth in key ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.competitorC.com/products/</td>\n",
              "      <td>Product Page: Our Core Offering</td>\n",
              "      <td>Details about our main product, its features, ...</td>\n",
              "      <td>Details about our main product, its features, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c60928e3-f38b-4727-9efc-8fa561876617')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c60928e3-f38b-4727-9efc-8fa561876617 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c60928e3-f38b-4727-9efc-8fa561876617');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-37f258b2-e9e0-4df2-bbc8-beb1f8aa9502\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-37f258b2-e9e0-4df2-bbc8-beb1f8aa9502')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-37f258b2-e9e0-4df2-bbc8-beb1f8aa9502 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_competitor_data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"https://www.competitorA.com/blog/\",\n          \"https://www.competitorB.com/press/\",\n          \"https://www.competitorC.com/products/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Blog Post 2: Product Update\",\n          \"Product Page: Our Core Offering\",\n          \"Press Release: Partnership Announcement\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Learn about the latest features and improvements in our flagship product...\",\n          \"Details about our main product, its features, benefits, and pricing...\",\n          \"We are excited to announce a strategic partnership with Company X to enhance our service offerings...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Learn about the latest features and improvements in our flagship product...\",\n          \"Details about our main product, its features, benefits, and pricing...\",\n          \"We are excited to announce a strategic partnership with Company X to enhance our service offerings...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35d546cc"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement a chunking strategy by splitting the cleaned text into smaller chunks and store them in a new DataFrame along with relevant metadata.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "183d10c9",
        "outputId": "d2a8419d-a764-4223-e3f7-c1bc7c210079"
      },
      "source": [
        "# Define a simple chunking strategy: split by sentences, with a maximum chunk size\n",
        "# and overlap. This is a basic example; more sophisticated chunking might use token limits.\n",
        "def chunk_text(text, max_chars=200, overlap=50):\n",
        "    \"\"\"Splits text into chunks with overlap.\"\"\"\n",
        "    sentences = text.split('. ') # Simple sentence splitting\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if len(current_chunk) + len(sentence) + 1 > max_chars and current_chunk:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            # Start new chunk with overlap\n",
        "            overlap_text = current_chunk[-overlap:] if len(current_chunk) >= overlap else current_chunk\n",
        "            current_chunk = overlap_text + \". \" + sentence\n",
        "        else:\n",
        "            current_chunk += ('. ' if current_chunk else '') + sentence\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Apply the chunking strategy and create a new DataFrame for chunks\n",
        "chunked_data = []\n",
        "for index, row in df_competitor_data.iterrows():\n",
        "    chunks = chunk_text(row['cleaned_content'])\n",
        "    for chunk in chunks:\n",
        "        chunked_data.append({\n",
        "            'source': row['source'],\n",
        "            'title': row['title'],\n",
        "            'chunk': chunk\n",
        "        })\n",
        "\n",
        "df_chunks = pd.DataFrame(chunked_data)\n",
        "\n",
        "display(df_chunks.head())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                  source  \\\n",
              "0      https://www.competitorA.com/blog/   \n",
              "1      https://www.competitorA.com/blog/   \n",
              "2     https://www.competitorB.com/press/   \n",
              "3     https://www.competitorB.com/press/   \n",
              "4  https://www.competitorC.com/products/   \n",
              "\n",
              "                                     title  \\\n",
              "0            Blog Post 1: Our New Strategy   \n",
              "1              Blog Post 2: Product Update   \n",
              "2  Press Release: Partnership Announcement   \n",
              "3         Press Release: Quarterly Results   \n",
              "4          Product Page: Our Core Offering   \n",
              "\n",
              "                                               chunk  \n",
              "0  This post discusses our innovative approach to...  \n",
              "1  Learn about the latest features and improvemen...  \n",
              "2  We are excited to announce a strategic partner...  \n",
              "3  Our Q2 results show significant growth in key ...  \n",
              "4  Details about our main product, its features, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7fee10ba-df6f-49dd-9e4b-41a7e4028e5b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>title</th>\n",
              "      <th>chunk</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.competitorA.com/blog/</td>\n",
              "      <td>Blog Post 1: Our New Strategy</td>\n",
              "      <td>This post discusses our innovative approach to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.competitorA.com/blog/</td>\n",
              "      <td>Blog Post 2: Product Update</td>\n",
              "      <td>Learn about the latest features and improvemen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.competitorB.com/press/</td>\n",
              "      <td>Press Release: Partnership Announcement</td>\n",
              "      <td>We are excited to announce a strategic partner...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.competitorB.com/press/</td>\n",
              "      <td>Press Release: Quarterly Results</td>\n",
              "      <td>Our Q2 results show significant growth in key ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.competitorC.com/products/</td>\n",
              "      <td>Product Page: Our Core Offering</td>\n",
              "      <td>Details about our main product, its features, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fee10ba-df6f-49dd-9e4b-41a7e4028e5b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7fee10ba-df6f-49dd-9e4b-41a7e4028e5b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7fee10ba-df6f-49dd-9e4b-41a7e4028e5b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a425e0d6-0102-4525-b078-1a600fd51ea3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a425e0d6-0102-4525-b078-1a600fd51ea3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a425e0d6-0102-4525-b078-1a600fd51ea3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_chunks\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"https://www.competitorA.com/blog/\",\n          \"https://www.competitorB.com/press/\",\n          \"https://www.competitorC.com/products/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Blog Post 2: Product Update\",\n          \"Product Page: Our Core Offering\",\n          \"Press Release: Partnership Announcement\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunk\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Learn about the latest features and improvements in our flagship product...\",\n          \"Details about our main product, its features, benefits, and pricing...\",\n          \"We are excited to announce a strategic partnership with Company X to enhance our service offerings...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "158e5a48"
      },
      "source": [
        "## Set up the vector database\n",
        "\n",
        "### Subtask:\n",
        "Choose and set up a vector database (like ChromaDB, FAISS, etc.) to store the embeddings of the competitor data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40a19c45"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary library for ChromaDB and initialize the client and collection to store the data embeddings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc98564b",
        "outputId": "4f85d77c-7960-47f4-e994-e008c72346d4"
      },
      "source": [
        "import chromadb\n",
        "\n",
        "# 2. Initialize or connect to the vector database\n",
        "# By default, ChromaDB will create a persistent client in a directory named \"chroma_db\"\n",
        "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "# 3. Create a collection within the database\n",
        "collection_name = \"competitor_marketing_intelligence\"\n",
        "collection = client.get_or_create_collection(name=collection_name)\n",
        "\n",
        "print(f\"Vector database initialized and collection '{collection_name}' created or accessed.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector database initialized and collection 'competitor_marketing_intelligence' created or accessed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d10518b5"
      },
      "source": [
        "## Implement embedding\n",
        "\n",
        "### Subtask:\n",
        "Use a suitable embedding model to convert the text chunks into numerical vectors and store them in the vector database.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a1b1bb9"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the embedding model and tokenizer, then iterate through the chunks DataFrame to generate embeddings and add them to the ChromaDB collection.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368,
          "referenced_widgets": [
            "31c62405460d4332a6dc5575ae77dab4",
            "81114738ed274e18bc641164fc346fa3",
            "6fb0362643b749408253c76e3262c701",
            "0bcf79a36ada4e11a30aa663eb67f6fa",
            "19a897354fb9467d8b16795f98b7c517",
            "d914b098249b447ea86c6961ecbb61fe",
            "f89c591a911d4ed9966170776798b7b8",
            "fdb3eb40d9704e2a835d1cbad801ebc0",
            "c526582e6bf14d1ca7d8674514f20f9a",
            "8cf7f80fb48a4f5da4bd68333454f2b5",
            "39482982553f4d80953dfcb289d53f7b",
            "f1f3ec3e0ed3417ea5a9c5cc22903f2d",
            "2e9ffbae21e6499bbb27ddde463fc2ef",
            "00c1fa5dde5448039cd07c2259a438ee",
            "8fd3c794d3ae4dd3b96f638d95cb317f",
            "07f3242827a444a088ba3e421425b374",
            "3f3e038082ea4ecabd27ea75a29870f5",
            "d22b6288f03d4154b3be677bb1925ca3",
            "7f98f3c551b84b92b45b34cb1ef8f449",
            "eb936c2848094068bbd44f4bc9e2cc8e",
            "ed5e4fee895e4dbcaf502ca737409400",
            "6d022fd5fa474ddfbabbadf3b6e6f794",
            "f4de0f7f3f424c48b23c05e8b186f03e",
            "4ab11eb392544e45aa28c7645b695dd0",
            "37a0fa8dca8542d19770f5369303b14b",
            "58de70e9cf8f43b5aaa9e92aaafe5faa",
            "618c385604e7407fb7c5abaf7b28a398",
            "0b2e136b95a0487cb7269c784115c228",
            "6b5e815d1851409bad2eb828bf9d226d",
            "c3600f18491d40139bb45ee3f790b066",
            "d8f5170231b041d4be23cb8cb652f172",
            "c3d031adc16a4daea0ddd8c4d06279cd",
            "49b342a5cfe445eea10a3939b1886c63",
            "c98bdaf26d46435397d56479f4bd641a",
            "55a3295202374b7d923e4512f0e1738c",
            "14fbf46c4810435c9fd922636277a82f",
            "8fe22f858b8a4f5db9333844f89e0e7a",
            "aea4b9144f6c40119f882583637e877d",
            "fb056ec988bc4ef09ebe559093bb5d54",
            "ac2e77a3c43d4c10a1d0f67d26083197",
            "6ee5d085e454499d97fcabe909261956",
            "1891e6a5d432485493932e7fb5bfa228",
            "bcbdfcdfdb3b4d4397d82f39064960f0",
            "3c63950056c14d03bc2a38ab52dc5278",
            "c8a8b61a50b34da28b69c17bed67f51d",
            "dea2c68ad245478b9f45de2b2d55c7a4",
            "00cfb80713e24aaf871852db53036a4f",
            "32a51397aeea49839cf9008e2d72906d",
            "860d96ed19e44c5a9f59f69812873a16",
            "332cbc12aabd413aaa2c44c0f0357810",
            "323a5cfc9d24414cb2fda1452579cd02",
            "8595d04b5ac04373a35bae73c8f2b4d0",
            "3fb94271bd6843a2a91222ab37330e5e",
            "7a3e18466f8a4ac4a410fb513958156a",
            "dd1f953e6f794116ae485fa858d2b21c",
            "2db0c74e727a4600b39c6b58a875f522",
            "608db02108de4171b66c93d162ecbdd2",
            "b16b24425119476daf4957f90d8a0f00",
            "a61965dbfad64a24be1a11fcbba4ae38",
            "52e19ef21e974b4384b01b87c4c0399c",
            "ca7014c045844b40bf4f208accf7a4aa",
            "198c04610f0140bea6041c057d2a54e4",
            "d3b67dc8fedf4c58bdb3388b373c0f14",
            "730e23f51bb64115b316a305313f0341",
            "476eca90b9204ea88049dae1400e43a5",
            "64e8f6b438b94bec99196cddd268c9a2"
          ]
        },
        "id": "a6dc988a",
        "outputId": "0f11c937-b011-492c-f087-2e1e7d1bec2b"
      },
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "import uuid\n",
        "\n",
        "# 1. Choose and load an appropriate embedding model and tokenizer\n",
        "# Using a pre-trained model from Hugging Face transformers\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Function to get embeddings\n",
        "def get_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # Get the embeddings from the last hidden state, take the mean of the token embeddings\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().tolist()\n",
        "    return embeddings\n",
        "\n",
        "# 3. Iterate through the df_chunks DataFrame\n",
        "embeddings_to_add = []\n",
        "metadatas_to_add = []\n",
        "ids_to_add = []\n",
        "\n",
        "for index, row in df_chunks.iterrows():\n",
        "    chunk_text = row['chunk']\n",
        "    source = row['source']\n",
        "    title = row['title']\n",
        "\n",
        "    # 4. Generate embedding for each chunk\n",
        "    embedding = get_embedding(chunk_text)\n",
        "\n",
        "    # Generate a unique ID for each entry\n",
        "    unique_id = str(uuid.uuid4())\n",
        "\n",
        "    # 5. Add the generated embeddings and metadata to the lists\n",
        "    embeddings_to_add.append(embedding)\n",
        "    metadatas_to_add.append({\"source\": source, \"title\": title, \"text_chunk\": chunk_text})\n",
        "    ids_to_add.append(unique_id)\n",
        "\n",
        "# Add all the chunks to the ChromaDB collection in a batch\n",
        "if embeddings_to_add:\n",
        "    collection.add(\n",
        "        embeddings=embeddings_to_add,\n",
        "        metadatas=metadatas_to_add,\n",
        "        ids=ids_to_add\n",
        "    )\n",
        "    print(f\"Added {len(embeddings_to_add)} chunks to the '{collection_name}' collection.\")\n",
        "\n",
        "# Verify by counting the items in the collection\n",
        "print(f\"Total items in collection: {collection.count()}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31c62405460d4332a6dc5575ae77dab4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1f3ec3e0ed3417ea5a9c5cc22903f2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4de0f7f3f424c48b23c05e8b186f03e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c98bdaf26d46435397d56479f4bd641a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8a8b61a50b34da28b69c17bed67f51d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2db0c74e727a4600b39c6b58a875f522"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 5 chunks to the 'competitor_marketing_intelligence' collection.\n",
            "Total items in collection: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1234ef91"
      },
      "source": [
        "## Develop the rag system\n",
        "\n",
        "### Subtask:\n",
        "Build the RAG system to retrieve relevant information from the vector database based on user queries (e.g., \"What is Competitor X's strategy for feature Y?\").\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61d6799d"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a function to perform a similarity search in the vector database using a user query, generate an embedding for the query, and return the relevant chunks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59fe09de",
        "outputId": "0458a28a-af1b-4909-c3f8-4aedd1784b91"
      },
      "source": [
        "def retrieve_relevant_chunks(query, collection, model, tokenizer, n_results=3):\n",
        "    \"\"\"\n",
        "    Retrieves relevant text chunks from the vector database based on a user query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The user's query string.\n",
        "        collection: The ChromaDB collection object.\n",
        "        model: The pre-trained embedding model.\n",
        "        tokenizer: The tokenizer for the embedding model.\n",
        "        n_results (int): The number of results to retrieve.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, where each dictionary contains information\n",
        "              about a retrieved chunk (e.g., text, source, title).\n",
        "    \"\"\"\n",
        "    # Generate embedding for the user query\n",
        "    query_embedding = get_embedding(query) # Reuse the get_embedding function from previous step\n",
        "\n",
        "    # Perform similarity search in the ChromaDB collection\n",
        "    results = collection.query(\n",
        "        query_embeddings=[query_embedding],\n",
        "        n_results=n_results,\n",
        "        include=['metadatas', 'documents']\n",
        "    )\n",
        "\n",
        "    # Extract relevant chunks from the results\n",
        "    retrieved_chunks = []\n",
        "    if results and results.get('metadatas') and results.get('documents'):\n",
        "        for metadata, document in zip(results['metadatas'][0], results['documents'][0]):\n",
        "            retrieved_chunks.append({\n",
        "                'source': metadata.get('source'),\n",
        "                'title': metadata.get('title'),\n",
        "                'chunk': document # The document field contains the text chunk\n",
        "            })\n",
        "\n",
        "    return retrieved_chunks\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'collection', 'model', and 'tokenizer' are already defined from previous steps\n",
        "user_query = \"What is Competitor A's new strategy?\"\n",
        "relevant_chunks = retrieve_relevant_chunks(user_query, collection, model, tokenizer, n_results=2)\n",
        "\n",
        "# Display the retrieved chunks\n",
        "print(f\"Retrieving relevant chunks for query: '{user_query}'\")\n",
        "if relevant_chunks:\n",
        "    for i, chunk_info in enumerate(relevant_chunks):\n",
        "        print(f\"\\n--- Retrieved Chunk {i+1} ---\")\n",
        "        print(f\"Source: {chunk_info['source']}\")\n",
        "        print(f\"Title: {chunk_info['title']}\")\n",
        "        print(f\"Chunk: {chunk_info['chunk']}\")\n",
        "else:\n",
        "    print(\"No relevant chunks found.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving relevant chunks for query: 'What is Competitor A's new strategy?'\n",
            "\n",
            "--- Retrieved Chunk 1 ---\n",
            "Source: https://www.competitorB.com/press/\n",
            "Title: Press Release: Partnership Announcement\n",
            "Chunk: None\n",
            "\n",
            "--- Retrieved Chunk 2 ---\n",
            "Source: https://www.competitorB.com/press/\n",
            "Title: Press Release: Quarterly Results\n",
            "Chunk: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af448116"
      },
      "source": [
        "**Reasoning**:\n",
        "The retrieved chunks show 'None' for the 'chunk' field, which is incorrect. The relevant text should be in the 'documents' field of the query results. The previous code incorrectly assigned `document` which is None to the chunk field. I need to fix the function to correctly extract the text content from the results and re-run the function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47877176",
        "outputId": "dbea59cb-78b7-487d-98f6-a1095107638b"
      },
      "source": [
        "def retrieve_relevant_chunks(query, collection, model, tokenizer, n_results=3):\n",
        "    \"\"\"\n",
        "    Retrieves relevant text chunks from the vector database based on a user query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The user's query string.\n",
        "        collection: The ChromaDB collection object.\n",
        "        model: The pre-trained embedding model.\n",
        "        tokenizer: The tokenizer for the embedding model.\n",
        "        n_results (int): The number of results to retrieve.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, where each dictionary contains information\n",
        "              about a retrieved chunk (e.g., text, source, title).\n",
        "    \"\"\"\n",
        "    # Generate embedding for the user query\n",
        "    query_embedding = get_embedding(query) # Reuse the get_embedding function from previous step\n",
        "\n",
        "    # Perform similarity search in the ChromaDB collection\n",
        "    results = collection.query(\n",
        "        query_embeddings=[query_embedding],\n",
        "        n_results=n_results,\n",
        "        include=['metadatas', 'documents']\n",
        "    )\n",
        "\n",
        "    # Extract relevant chunks from the results\n",
        "    retrieved_chunks = []\n",
        "    if results and results.get('metadatas') and results.get('documents'):\n",
        "        for metadata, document_content in zip(results['metadatas'][0], results['documents'][0]):\n",
        "            retrieved_chunks.append({\n",
        "                'source': metadata.get('source'),\n",
        "                'title': metadata.get('title'),\n",
        "                'chunk': document_content # The document field contains the text chunk\n",
        "            })\n",
        "\n",
        "    return retrieved_chunks\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'collection', 'model', and 'tokenizer' are already defined from previous steps\n",
        "user_query = \"What is Competitor A's new strategy?\"\n",
        "relevant_chunks = retrieve_relevant_chunks(user_query, collection, model, tokenizer, n_results=2)\n",
        "\n",
        "# Display the retrieved chunks\n",
        "print(f\"Retrieving relevant chunks for query: '{user_query}'\")\n",
        "if relevant_chunks:\n",
        "    for i, chunk_info in enumerate(relevant_chunks):\n",
        "        print(f\"\\n--- Retrieved Chunk {i+1} ---\")\n",
        "        print(f\"Source: {chunk_info['source']}\")\n",
        "        print(f\"Title: {chunk_info['title']}\")\n",
        "        print(f\"Chunk: {chunk_info['chunk']}\")\n",
        "else:\n",
        "    print(\"No relevant chunks found.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving relevant chunks for query: 'What is Competitor A's new strategy?'\n",
            "\n",
            "--- Retrieved Chunk 1 ---\n",
            "Source: https://www.competitorB.com/press/\n",
            "Title: Press Release: Partnership Announcement\n",
            "Chunk: None\n",
            "\n",
            "--- Retrieved Chunk 2 ---\n",
            "Source: https://www.competitorB.com/press/\n",
            "Title: Press Release: Quarterly Results\n",
            "Chunk: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ef70ca6"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to retrieve chunk content failed. It seems the documents are not being returned correctly by the ChromaDB query. I need to investigate why the 'documents' field is returning `None`. I will try to query the collection directly using the IDs to see if the documents were stored correctly in the first place. If they were not, I need to go back and fix the embedding and storing process. If they were, I need to figure out why the `query` function is not returning them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "862d8aaf",
        "outputId": "ff305a52-77b4-4f77-87e4-522dab2884c3"
      },
      "source": [
        "# Verify the contents of the collection by retrieving some items by ID\n",
        "# Assuming 'ids_to_add' from the embedding step contains the IDs of the added documents\n",
        "# If ids_to_add is not available, we can try listing the collection contents\n",
        "try:\n",
        "    collection_count = collection.count()\n",
        "    if collection_count > 0:\n",
        "        # Retrieve the first few items to inspect their structure\n",
        "        retrieved_items = collection.get(\n",
        "            limit=3,\n",
        "            include=['metadatas', 'documents', 'embeddings']\n",
        "        )\n",
        "        print(\"\\n--- Verifying Collection Contents ---\")\n",
        "        print(retrieved_items)\n",
        "    else:\n",
        "        print(\"\\nCollection is empty. No items to verify.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nError retrieving items from collection: {e}\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Verifying Collection Contents ---\n",
            "{'ids': ['681c56e6-d8cb-4ca7-976b-009870995e3c', 'bfb47b87-eefd-47cf-aa5c-f8c9bc3814ef', 'e85c1094-60bf-4248-b3ab-c947fc68945a'], 'embeddings': array([[-0.09707531, -0.18320671, -0.01266541, ..., -0.20415442,\n",
            "        -0.01751971,  0.27394196],\n",
            "       [ 0.03519366,  0.04157192,  0.27393839, ..., -0.22568724,\n",
            "         0.20910706,  0.39824942],\n",
            "       [-0.00792628, -0.24916808,  0.05880607, ..., -0.39672151,\n",
            "         0.05634578, -0.01143538]]), 'documents': ['This post discusses our innovative approach to market expansion and customer engagement...', 'Learn about the latest features and improvements in our flagship product...', 'We are excited to announce a strategic partnership with Company X to enhance our service offerings...'], 'uris': None, 'included': ['metadatas', 'documents', 'embeddings'], 'data': None, 'metadatas': [{'source': 'https://www.competitorA.com/blog/', 'title': 'Blog Post 1: Our New Strategy'}, {'title': 'Blog Post 2: Product Update', 'source': 'https://www.competitorA.com/blog/'}, {'source': 'https://www.competitorB.com/press/', 'title': 'Press Release: Partnership Announcement'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5971ad0c"
      },
      "source": [
        "**Reasoning**:\n",
        "The verification step shows that the 'documents' field is indeed `None` when retrieving items directly by ID, but the 'metadatas' field *does* contain the 'text_chunk'. This indicates the chunk text was stored as metadata, not in the dedicated 'documents' field as intended for a RAG system to use directly. I need to modify the `collection.add` call in the embedding step to store the chunk text in the `documents` parameter, not just in the `metadatas`. After fixing this, I will re-run the embedding step to correctly populate the database and then re-test the retrieval function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dc4a990",
        "outputId": "b1964086-ef9e-410a-b75c-40fc3b1e39b7"
      },
      "source": [
        "# Re-implement the embedding and adding to collection step to store text in 'documents'\n",
        "\n",
        "embeddings_to_add = []\n",
        "metadatas_to_add = [] # Metadata will now only contain source and title\n",
        "documents_to_add = [] # Text chunks will go here\n",
        "ids_to_add = []\n",
        "\n",
        "for index, row in df_chunks.iterrows():\n",
        "    chunk_text = row['chunk']\n",
        "    source = row['source']\n",
        "    title = row['title']\n",
        "\n",
        "    # Generate embedding for each chunk\n",
        "    embedding = get_embedding(chunk_text)\n",
        "\n",
        "    # Generate a unique ID for each entry\n",
        "    unique_id = str(uuid.uuid4())\n",
        "\n",
        "    # Add the generated embeddings, metadata, and documents to the lists\n",
        "    embeddings_to_add.append(embedding)\n",
        "    metadatas_to_add.append({\"source\": source, \"title\": title}) # Store source and title as metadata\n",
        "    documents_to_add.append(chunk_text) # Store the text chunk in the documents list\n",
        "    ids_to_add.append(unique_id)\n",
        "\n",
        "# Clear the existing collection before adding new data with the correct structure\n",
        "collection.delete(ids=[id for id in collection.get()['ids']])\n",
        "print(f\"Cleared existing items from collection.\")\n",
        "\n",
        "\n",
        "# Add all the chunks to the ChromaDB collection in a batch, storing text in 'documents'\n",
        "if embeddings_to_add:\n",
        "    collection.add(\n",
        "        embeddings=embeddings_to_add,\n",
        "        metadatas=metadatas_to_add,\n",
        "        documents=documents_to_add, # Correctly pass the documents list\n",
        "        ids=ids_to_add\n",
        "    )\n",
        "    print(f\"Added {len(embeddings_to_add)} chunks to the '{collection_name}' collection with text in 'documents'.\")\n",
        "\n",
        "# Verify by counting the items in the collection\n",
        "print(f\"Total items in collection after re-adding: {collection.count()}\")\n",
        "\n",
        "# Re-test the retrieve_relevant_chunks function\n",
        "user_query = \"What is Competitor A's new strategy?\"\n",
        "relevant_chunks = retrieve_relevant_chunks(user_query, collection, model, tokenizer, n_results=2)\n",
        "\n",
        "# Display the retrieved chunks\n",
        "print(f\"\\nRetrieving relevant chunks for query: '{user_query}'\")\n",
        "if relevant_chunks:\n",
        "    for i, chunk_info in enumerate(relevant_chunks):\n",
        "        print(f\"\\n--- Retrieved Chunk {i+1} ---\")\n",
        "        print(f\"Source: {chunk_info['source']}\")\n",
        "        print(f\"Title: {chunk_info['title']}\")\n",
        "        print(f\"Chunk: {chunk_info['chunk']}\")\n",
        "else:\n",
        "    print(\"No relevant chunks found.\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleared existing items from collection.\n",
            "Added 5 chunks to the 'competitor_marketing_intelligence' collection with text in 'documents'.\n",
            "Total items in collection after re-adding: 5\n",
            "\n",
            "Retrieving relevant chunks for query: 'What is Competitor A's new strategy?'\n",
            "\n",
            "--- Retrieved Chunk 1 ---\n",
            "Source: https://www.competitorB.com/press/\n",
            "Title: Press Release: Partnership Announcement\n",
            "Chunk: We are excited to announce a strategic partnership with Company X to enhance our service offerings...\n",
            "\n",
            "--- Retrieved Chunk 2 ---\n",
            "Source: https://www.competitorB.com/press/\n",
            "Title: Press Release: Quarterly Results\n",
            "Chunk: Our Q2 results show significant growth in key segments and strong market position...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74b43ac8"
      },
      "source": [
        "## Integrate with an llm\n",
        "\n",
        "### Subtask:\n",
        "Connect the RAG system with an LLM (e.g., a model from the `transformers` library, or an external API like Gemini, OpenAI, etc.) to generate counter-strategies based on the retrieved information and the user's request.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39051652"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to choose and load an LLM and its tokenizer, define a function to generate counter-strategies using the LLM and retrieved chunks, format the prompt within that function, pass it to the LLM, and return the result. This can be done in a single code block. I will use a model from the `transformers` library for this example, similar to the embedding model. Given the time constraints, I will use a relatively small model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33ab8766",
        "outputId": "e17ff2f9-6c5b-4c75-edd1-394be48811e1"
      },
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "# 1. Choose and load an appropriate LLM and its tokenizer\n",
        "# Using a small causal language model from Hugging Face for demonstration\n",
        "# You might need to change this model based on your needs and available resources\n",
        "llm_model_name = \"distilgpt2\" # A small, fast model for demonstration\n",
        "llm_tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(llm_model_name)\n",
        "\n",
        "# Create a text generation pipeline for ease of use\n",
        "generator = pipeline(\"text-generation\", model=llm_model, tokenizer=llm_tokenizer)\n",
        "\n",
        "# 2. Define a function that takes a user query and the retrieved relevant chunks as input\n",
        "def generate_counter_strategy(user_query, retrieved_chunks):\n",
        "    \"\"\"\n",
        "    Generates a counter-strategy based on the user query and retrieved information.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's query (e.g., \"How to counter Competitor A's new strategy?\").\n",
        "        retrieved_chunks (list): A list of dictionaries containing relevant information chunks.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated counter-strategy.\n",
        "    \"\"\"\n",
        "    # 3. Format the retrieved chunks and the user query into a single prompt\n",
        "    context = \"\\n\\n\".join([f\"Source: {c['source']}\\nTitle: {c['title']}\\nContent: {c['chunk']}\" for c in retrieved_chunks])\n",
        "\n",
        "    prompt = f\"\"\"Given the following information about competitors:\n",
        "\n",
        "{context}\n",
        "\n",
        "Based on this information, generate a counter-strategy for our sales and marketing teams to address the user's request: \"{user_query}\"\n",
        "\n",
        "Counter-Strategy:\n",
        "\"\"\"\n",
        "\n",
        "    # 4. Pass the formatted prompt to the LLM to generate a response\n",
        "    # Need to set pad_token_id for generation with models like GPT-2 that don't have one by default\n",
        "    if llm_tokenizer.pad_token_id is None:\n",
        "        llm_tokenizer.pad_token_id = llm_tokenizer.eos_token_id\n",
        "\n",
        "    response = generator(prompt, max_length=500, num_return_sequences=1, truncation=True)[0]['generated_text']\n",
        "\n",
        "    # 5. Return the generated counter-strategy from the function\n",
        "    # Clean up the response to only return the generated strategy part\n",
        "    strategy_prefix = \"Counter-Strategy:\\n\"\n",
        "    if strategy_prefix in response:\n",
        "        generated_strategy = response.split(strategy_prefix, 1)[1].strip()\n",
        "    else:\n",
        "        generated_strategy = response.strip() # Return the whole response if prefix not found\n",
        "\n",
        "    return generated_strategy\n",
        "\n",
        "# Example Usage:\n",
        "# Assuming 'user_query' and 'relevant_chunks' are available from the previous step\n",
        "# user_query = \"How should our sales team respond to Competitor B's partnership announcement?\"\n",
        "# relevant_chunks = retrieve_relevant_chunks(user_query, collection, model, tokenizer, n_results=3) # Use the function from the previous step\n",
        "\n",
        "# if relevant_chunks:\n",
        "#     counter_strategy = generate_counter_strategy(user_query, relevant_chunks)\n",
        "#     print(\"\\n--- Generated Counter-Strategy ---\")\n",
        "#     print(counter_strategy)\n",
        "# else:\n",
        "#     print(\"\\nCould not generate counter-strategy as no relevant information was retrieved.\")\n",
        "\n",
        "# The LLM and tokenizer are loaded, and the function is defined.\n",
        "# The function will be called in the next step with actual retrieved chunks.\n",
        "print(\"LLM and tokenizer loaded, generate_counter_strategy function defined.\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM and tokenizer loaded, generate_counter_strategy function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ce1daed"
      },
      "source": [
        "**Reasoning**:\n",
        "The LLM and the `generate_counter_strategy` function are defined. Now I need to demonstrate the function's usage by calling it with the previously retrieved relevant chunks and a user query, then display the generated counter-strategy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "oaLjrQgjVkNc",
        "outputId": "9836b70b-d6f1-4bab-e27d-2af754f34a0a"
      },
      "source": [
        "# Example Usage: Call the generate_counter_strategy function with a user query and the retrieved chunks\n",
        "# Assuming 'relevant_chunks' is available from the previous retrieval step\n",
        "\n",
        "user_query = \"How should our sales team respond to Competitor B's partnership announcement?\"\n",
        "\n",
        "# In a real scenario, you would call retrieve_relevant_chunks here:\n",
        "# relevant_chunks = retrieve_relevant_chunks(user_query, collection, model, tokenizer, n_results=3)\n",
        "\n",
        "# For demonstration, we'll use the 'retrieved_items' variable from the RAG system development step\n",
        "# which contains example retrieved data, reformatting it to match the expected input of generate_counter_strategy\n",
        "# Note: This is a simplification. In a full pipeline, you would directly use the output of retrieve_relevant_chunks.\n",
        "\n",
        "# Check if retrieved_items is available and has the expected structure\n",
        "if 'retrieved_items' in locals() and retrieved_items and retrieved_items.get('documents'):\n",
        "    # Reformat retrieved_items into the list of dictionaries expected by generate_counter_strategy\n",
        "    relevant_chunks_for_llm = []\n",
        "    for i in range(len(retrieved_items['documents'])):\n",
        "        relevant_chunks_for_llm.append({\n",
        "            'source': retrieved_items['metadatas'][i].get('source', 'N/A'),\n",
        "            'title': retrieved_items['metadatas'][i'].get('title', 'N/A'),\n",
        "            'chunk': retrieved_items['documents'][i]\n",
        "        })\n",
        "\n",
        "    if relevant_chunks_for_llm:\n",
        "        counter_strategy = generate_counter_strategy(user_query, relevant_chunks_for_llm)\n",
        "        print(\"\\n--- Generated Counter-Strategy ---\")\n",
        "        print(counter_strategy)\n",
        "    else:\n",
        "        print(\"\\nCould not generate counter-strategy as no relevant information was available from retrieved_items.\")\n",
        "else:\n",
        "    print(\"\\n'retrieved_items' variable not found or does not contain the expected data. Cannot demonstrate LLM generation.\")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 20) (ipython-input-3392025457.py, line 20)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3392025457.py\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    'title': retrieved_items['metadatas'][i'].get('title', 'N/A'),\u001b[0m\n\u001b[0m                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16f86f1f"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed due to a `SyntaxError` in the string literal `'metadatas'[i']`. I need to fix this syntax error and re-run the code block to call the `generate_counter_strategy` function and display the result.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsza7F4PVl7G",
        "outputId": "1c8a13f8-66c7-4d4f-b038-9e6ce63202a1"
      },
      "source": [
        "# Example Usage: Call the generate_counter_strategy function with a user query and the retrieved chunks\n",
        "# Assuming 'relevant_chunks' is available from the previous retrieval step\n",
        "\n",
        "user_query = \"How should our sales team respond to Competitor B's partnership announcement?\"\n",
        "\n",
        "# In a real scenario, you would call retrieve_relevant_chunks here:\n",
        "# relevant_chunks = retrieve_relevant_chunks(user_query, collection, model, tokenizer, n_results=3)\n",
        "\n",
        "# For demonstration, we'll use the 'retrieved_items' variable from the RAG system development step\n",
        "# which contains example retrieved data, reformatting it to match the expected input of generate_counter_strategy\n",
        "# Note: This is a simplification. In a full pipeline, you would directly use the output of retrieve_relevant_chunks.\n",
        "\n",
        "# Check if retrieved_items is available and has the expected structure\n",
        "if 'retrieved_items' in locals() and retrieved_items and retrieved_items.get('documents'):\n",
        "    # Reformat retrieved_items into the list of dictionaries expected by generate_counter_strategy\n",
        "    relevant_chunks_for_llm = []\n",
        "    for i in range(len(retrieved_items['documents'])):\n",
        "        relevant_chunks_for_llm.append({\n",
        "            'source': retrieved_items['metadatas'][i].get('source', 'N/A'),\n",
        "            'title': retrieved_items['metadatas'][i].get('title', 'N/A'), # Fixed the syntax error here\n",
        "            'chunk': retrieved_items['documents'][i]\n",
        "        })\n",
        "\n",
        "    if relevant_chunks_for_llm:\n",
        "        counter_strategy = generate_counter_strategy(user_query, relevant_chunks_for_llm)\n",
        "        print(\"\\n--- Generated Counter-Strategy ---\")\n",
        "        print(counter_strategy)\n",
        "    else:\n",
        "        print(\"\\nCould not generate counter-strategy as no relevant information was available from retrieved_items.\")\n",
        "else:\n",
        "    print(\"\\n'retrieved_items' variable not found or does not contain the expected data. Cannot demonstrate LLM generation.\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=500) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Generated Counter-Strategy ---\n",
            "Product Update:\n",
            "This post focuses on the new strategy for Product Update as part of the ongoing collaboration between Company X and Company Y. This strategy emphasizes our approach to market expansion and customer engagement...\n",
            "Source: https://www.competitorA.com/blog/\n",
            "Title: Report\n",
            "Content: Review\n",
            "Content: We are excited to announce a strategy for Product Update as part of the ongoing collaboration between Company X and Company Y. This strategy emphasizes our approach to market expansion and customer engagement...\n",
            "Source: https://www.competitorA.com/blog/\n",
            "Title: Report\n",
            "Content: We are excited to announce a strategy for Product Update as part of the ongoing collaboration between Company X and Company Y. This strategy emphasizes our approach to market expansion and customer engagement...\n",
            "Source: https://www.competitorA.com/blog/\n",
            "Title: Report\n",
            "Content: We are excited to announce a strategy for Product Update as part of the ongoing collaboration between Company X and Company Y. This strategy emphasizes our approach to market expansion and customer engagement...\n",
            "Source: https://www.competitorA.com/blog/\n",
            "Title: Report\n",
            "Content: We are excited to announce a strategy for Product Update as part of the ongoing collaboration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e173cce"
      },
      "source": [
        "## Define strategy generation prompts\n",
        "\n",
        "### Subtask:\n",
        "Craft effective prompts for the LLM to guide it in generating actionable and strategic counter-responses for sales and marketing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9233421"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the `create_strategy_prompt` function to construct a detailed prompt for the LLM, incorporating the user query and retrieved chunks with specific instructions for generating actionable sales and marketing counter-strategies. Then, test the function with sample data and print the result.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23f025b7",
        "outputId": "43ab08fe-71f3-4b4e-c6ef-6c6691d17e8c"
      },
      "source": [
        "def create_strategy_prompt(user_query, retrieved_chunks):\n",
        "    \"\"\"\n",
        "    Crafts a detailed prompt for the LLM to generate actionable sales and marketing\n",
        "    counter-strategies based on a user query and retrieved competitor information.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's specific query about competitor strategy.\n",
        "        retrieved_chunks (list): A list of dictionaries, where each dictionary\n",
        "                                 contains 'source', 'title', and 'chunk' of\n",
        "                                 retrieved competitor data.\n",
        "\n",
        "    Returns:\n",
        "        str: The constructed prompt string for the LLM.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"You are a competitive intelligence analyst tasked with analyzing competitor information and generating actionable counter-strategies for our internal sales and marketing teams.\n",
        "\n",
        "Based on the following retrieved information about our competitors and the user's query, provide specific, actionable counter-strategies.\n",
        "\n",
        "Competitor Information:\n",
        "\"\"\"\n",
        "\n",
        "    if not retrieved_chunks:\n",
        "        prompt += \"No relevant competitor information was retrieved.\\n\"\n",
        "    else:\n",
        "        for i, chunk_info in enumerate(retrieved_chunks):\n",
        "            prompt += f\"\"\"\n",
        "--- Document {i+1} ---\n",
        "Source: {chunk_info.get('source', 'N/A')}\n",
        "Title: {chunk_info.get('title', 'N/A')}\n",
        "Content: {chunk_info.get('chunk', 'No content available.')}\n",
        "\"\"\"\n",
        "\n",
        "    prompt += f\"\"\"\n",
        "\n",
        "User Query: {user_query}\n",
        "\n",
        "Based on the competitor information and the user query, generate actionable counter-strategies specifically for our sales and marketing teams.\n",
        "\n",
        "Sales Strategies:\n",
        "Provide 3-5 concise, bullet-point strategies that our sales team can use in conversations, presentations, or negotiations. Focus on how to address competitor strengths, weaknesses, or specific announcements highlighted in the information.\n",
        "\n",
        "Marketing Strategies:\n",
        "Provide a paragraph (3-5 sentences) outlining key messaging points or campaign ideas that our marketing team can use to counter competitor narratives or leverage our advantages.\n",
        "\n",
        "Important Considerations:\n",
        "- Do NOT just summarize the competitor information.\n",
        "- Ensure the strategies are directly derived from and supported by the provided competitor information.\n",
        "- Make the strategies clear, practical, and actionable for sales and marketing professionals.\n",
        "- If the retrieved information is insufficient or irrelevant to the query, state that and explain why.\n",
        "\n",
        "Sales Strategies:\n",
        "\"\"\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "# Test the function with a sample user query and the 'relevant_chunks' variable\n",
        "# Assuming 'relevant_chunks' is available from the previous RAG step\n",
        "# If 'relevant_chunks' is not available, create a sample list for testing\n",
        "if 'relevant_chunks' not in locals() or not relevant_chunks:\n",
        "    print(\"Using sample data for testing as 'relevant_chunks' is not available or empty.\")\n",
        "    sample_relevant_chunks = [\n",
        "        {\n",
        "            'source': 'https://www.competitorA.com/blog/',\n",
        "            'title': 'Blog Post 1: Our New Strategy',\n",
        "            'chunk': 'This post discusses our innovative approach to market expansion and customer engagement...'\n",
        "        },\n",
        "        {\n",
        "            'source': 'https://www.competitorB.com/press/',\n",
        "            'title': 'Press Release: Partnership Announcement',\n",
        "            'chunk': 'We are excited to announce a strategic partnership with Company X to enhance our service offerings...'\n",
        "        }\n",
        "    ]\n",
        "else:\n",
        "    sample_relevant_chunks = relevant_chunks\n",
        "\n",
        "\n",
        "sample_user_query = \"How should our sales and marketing teams respond to Competitor B's partnership announcement?\"\n",
        "generated_prompt = create_strategy_prompt(sample_user_query, sample_relevant_chunks)\n",
        "\n",
        "# Print the generated prompt to review\n",
        "print(\"--- Generated LLM Prompt ---\")\n",
        "print(generated_prompt)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generated LLM Prompt ---\n",
            "You are a competitive intelligence analyst tasked with analyzing competitor information and generating actionable counter-strategies for our internal sales and marketing teams.\n",
            "\n",
            "Based on the following retrieved information about our competitors and the user's query, provide specific, actionable counter-strategies.\n",
            "\n",
            "Competitor Information:\n",
            "\n",
            "--- Document 1 ---\n",
            "Source: https://www.competitorB.com/press/\n",
            "Title: Press Release: Partnership Announcement\n",
            "Content: We are excited to announce a strategic partnership with Company X to enhance our service offerings...\n",
            "\n",
            "--- Document 2 ---\n",
            "Source: https://www.competitorB.com/press/\n",
            "Title: Press Release: Quarterly Results\n",
            "Content: Our Q2 results show significant growth in key segments and strong market position...\n",
            "\n",
            "\n",
            "User Query: How should our sales and marketing teams respond to Competitor B's partnership announcement?\n",
            "\n",
            "Based on the competitor information and the user query, generate actionable counter-strategies specifically for our sales and marketing teams.\n",
            "\n",
            "Sales Strategies:\n",
            "Provide 3-5 concise, bullet-point strategies that our sales team can use in conversations, presentations, or negotiations. Focus on how to address competitor strengths, weaknesses, or specific announcements highlighted in the information.\n",
            "\n",
            "Marketing Strategies:\n",
            "Provide a paragraph (3-5 sentences) outlining key messaging points or campaign ideas that our marketing team can use to counter competitor narratives or leverage our advantages.\n",
            "\n",
            "Important Considerations:\n",
            "- Do NOT just summarize the competitor information.\n",
            "- Ensure the strategies are directly derived from and supported by the provided competitor information.\n",
            "- Make the strategies clear, practical, and actionable for sales and marketing professionals.\n",
            "- If the retrieved information is insufficient or irrelevant to the query, state that and explain why.\n",
            "\n",
            "Sales Strategies:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91b46440"
      },
      "source": [
        "## Build a user interface (optional but recommended)\n",
        "\n",
        "### Subtask:\n",
        "Build a simple user interface using Gradio or Streamlit to easily input competitor data, pose queries, and view the generated strategies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "745fc0db"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary libraries for building the Gradio interface.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34e73200"
      },
      "source": [
        "import gradio as gr"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08b1a871"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the core logic function for the Gradio interface, including placeholder logic for retrieval and strategy generation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8032057"
      },
      "source": [
        "def generate_strategy_ui(user_query):\n",
        "    \"\"\"\n",
        "    Core logic function for the Gradio interface.\n",
        "    Takes a user query, performs retrieval and strategy generation.\n",
        "    \"\"\"\n",
        "    if not user_query:\n",
        "        return \"Please enter a query.\", \"Awaiting query...\", \"Awaiting query...\"\n",
        "\n",
        "    # 1. Retrieve relevant chunks based on the user query\n",
        "    # Ensure 'collection', 'model', and 'tokenizer' are accessible in this scope\n",
        "    # from previous steps where they were defined globally or passed appropriately.\n",
        "    # Assuming they are globally available for simplicity in this example.\n",
        "    try:\n",
        "        relevant_chunks = retrieve_relevant_chunks(user_query, collection, model, tokenizer, n_results=3)\n",
        "\n",
        "        if not relevant_chunks:\n",
        "            retrieved_info_display = \"No relevant competitor information found for this query.\"\n",
        "            generated_strategy = \"Could not generate a counter-strategy as no relevant information was retrieved.\"\n",
        "        else:\n",
        "            # Format the retrieved chunks for display\n",
        "            retrieved_info_display = \"Retrieved Competitor Information:\\n\\n\"\n",
        "            for i, chunk_info in enumerate(relevant_chunks):\n",
        "                retrieved_info_display += f\"--- Document {i+1} ---\\n\"\n",
        "                retrieved_info_display += f\"Source: {chunk_info.get('source', 'N/A')}\\n\"\n",
        "                retrieved_info_display += f\"Title: {chunk_info.get('title', 'N/A')}\\n\"\n",
        "                retrieved_info_display += f\"Content: {chunk_info.get('chunk', 'No content available.')}\\n\\n\"\n",
        "\n",
        "            # 2. Generate the counter-strategy using the LLM\n",
        "            # Ensure 'generate_counter_strategy' function and LLM components (generator, etc.)\n",
        "            # are accessible in this scope.\n",
        "            generated_strategy = generate_counter_strategy(user_query, relevant_chunks)\n",
        "\n",
        "    except Exception as e:\n",
        "        retrieved_info_display = f\"An error occurred during retrieval: {e}\"\n",
        "        generated_strategy = f\"An error occurred during strategy generation: {e}\"\n",
        "\n",
        "\n",
        "    return user_query, retrieved_info_display, generated_strategy"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd991f76"
      },
      "source": [
        "**Reasoning**:\n",
        "Create and launch the Gradio interface with appropriate input and output components.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "2175e920",
        "outputId": "c7ffa565-ce13-4551-e0af-1da38d50cbdb"
      },
      "source": [
        "# Create the Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=generate_strategy_ui,\n",
        "    inputs=gr.Textbox(label=\"Enter your query about competitor strategy:\", lines=2),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"User Query\", lines=1, interactive=False),\n",
        "        gr.Textbox(label=\"Retrieved Competitor Information (Placeholder)\", lines=5, interactive=False),\n",
        "        gr.Textbox(label=\"Generated Counter-Strategy (Placeholder)\", lines=10, interactive=False)\n",
        "    ],\n",
        "    title=\"Competitive Intelligence and Counter-Strategy Generator (UI Placeholder)\",\n",
        "    description=\"Enter a query about a competitor to simulate retrieval and strategy generation.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://be5b22e419ba509fb8.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://be5b22e419ba509fb8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13a2e326"
      },
      "source": [
        "## Evaluation and refinement\n",
        "\n",
        "### Subtask:\n",
        "Develop methods to evaluate the quality and relevance of the generated strategies and refine the RAG system and LLM prompts as needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9cde8a2"
      },
      "source": [
        "**Reasoning**:\n",
        "Define qualitative criteria for evaluating the generated strategies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e58eb00",
        "outputId": "8f82d599-1c02-4169-f8ee-aa03e3709845"
      },
      "source": [
        "# 1. Define qualitative criteria for evaluating the generated strategies\n",
        "\n",
        "evaluation_criteria = {\n",
        "    \"relevance\": \"How well does the generated strategy address the user's query and align with the retrieved competitor information? (Score 1-5)\",\n",
        "    \"actionability\": \"How specific, practical, and implementable is the strategy for sales and marketing teams? (Score 1-5)\",\n",
        "    \"clarity\": \"Is the strategy easy to understand and free of jargon? (Score 1-5)\",\n",
        "    \"coherence\": \"Is the strategy logically structured and consistent? (Score 1-5)\",\n",
        "    \"support_by_retrieval\": \"Is the strategy clearly supported by evidence from the retrieved competitor information? (Score 1-5)\",\n",
        "    \"originality_or_insight\": \"Does the strategy offer novel insights or go beyond a simple summary of the input? (Score 1-5)\",\n",
        "    \"overall_quality\": \"Overall assessment of the strategy's usefulness and quality. (Score 1-5)\",\n",
        "    \"comments\": \"Free-form comments on strengths, weaknesses, and suggestions for improvement.\"\n",
        "}\n",
        "\n",
        "print(\"Defined qualitative evaluation criteria:\")\n",
        "for criterion, description in evaluation_criteria.items():\n",
        "    print(f\"- {criterion}: {description}\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined qualitative evaluation criteria:\n",
            "- relevance: How well does the generated strategy address the user's query and align with the retrieved competitor information? (Score 1-5)\n",
            "- actionability: How specific, practical, and implementable is the strategy for sales and marketing teams? (Score 1-5)\n",
            "- clarity: Is the strategy easy to understand and free of jargon? (Score 1-5)\n",
            "- coherence: Is the strategy logically structured and consistent? (Score 1-5)\n",
            "- support_by_retrieval: Is the strategy clearly supported by evidence from the retrieved competitor information? (Score 1-5)\n",
            "- originality_or_insight: Does the strategy offer novel insights or go beyond a simple summary of the input? (Score 1-5)\n",
            "- overall_quality: Overall assessment of the strategy's usefulness and quality. (Score 1-5)\n",
            "- comments: Free-form comments on strengths, weaknesses, and suggestions for improvement.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2059692c"
      },
      "source": [
        "**Reasoning**:\n",
        "Outline a process for manually evaluating a sample of generated strategies based on the defined criteria.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2070276c",
        "outputId": "3db9bb86-6058-4476-b639-3168a07abc86"
      },
      "source": [
        "# 2. Outline a process for manually evaluating a sample of generated strategies\n",
        "\n",
        "evaluation_process_outline = \"\"\"\n",
        "Manual Evaluation Process for Generated Strategies:\n",
        "\n",
        "1.  **Select a Sample:** Choose a representative sample of user queries and their corresponding generated strategies and retrieved competitor information. The sample size should be manageable (e.g., 10-20 examples). Ensure variety in query types and the amount/relevance of retrieved data.\n",
        "\n",
        "2.  **Prepare Evaluation Packet:** For each item in the sample, create an evaluation packet containing:\n",
        "    *   The original user query.\n",
        "    *   The retrieved competitor information (source, title, and chunk text) that was fed to the LLM.\n",
        "    *   The generated counter-strategy from the LLM.\n",
        "    *   The qualitative evaluation criteria defined in the previous step.\n",
        "\n",
        "3.  **Assign Evaluators:** Have one or more human evaluators (ideally, individuals with relevant sales/marketing or competitive intelligence experience) review the evaluation packets.\n",
        "\n",
        "4.  **Conduct Evaluation:** For each packet, the evaluator should:\n",
        "    *   Read the user query and the retrieved competitor information to understand the context.\n",
        "    *   Read the generated counter-strategy.\n",
        "    *   Score the strategy based on each of the defined qualitative criteria (Relevance, Actionability, Clarity, Coherence, Support by Retrieval, Originality/Insight, Overall Quality) using the 1-5 scale.\n",
        "    *   Provide free-form comments detailing the strengths, weaknesses, and specific suggestions for improvement of the generated strategy.\n",
        "\n",
        "5.  **Aggregate and Analyze Results:** Collect all the evaluations. Aggregate the scores for each criterion across the sample. Analyze the comments to identify common themes, recurring issues, and specific areas where the strategies are strong or weak.\n",
        "\n",
        "6.  **Identify Areas for Refinement:** Based on the analysis, pinpoint specific aspects of the generated strategies that consistently score low or receive negative comments. This could relate to the strategy content itself, how well it uses the retrieved information, its practicality, etc.\n",
        "\"\"\"\n",
        "\n",
        "print(\"Manual Evaluation Process Outline:\")\n",
        "print(evaluation_process_outline)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual Evaluation Process Outline:\n",
            "\n",
            "Manual Evaluation Process for Generated Strategies:\n",
            "\n",
            "1.  **Select a Sample:** Choose a representative sample of user queries and their corresponding generated strategies and retrieved competitor information. The sample size should be manageable (e.g., 10-20 examples). Ensure variety in query types and the amount/relevance of retrieved data.\n",
            "\n",
            "2.  **Prepare Evaluation Packet:** For each item in the sample, create an evaluation packet containing:\n",
            "    *   The original user query.\n",
            "    *   The retrieved competitor information (source, title, and chunk text) that was fed to the LLM.\n",
            "    *   The generated counter-strategy from the LLM.\n",
            "    *   The qualitative evaluation criteria defined in the previous step.\n",
            "\n",
            "3.  **Assign Evaluators:** Have one or more human evaluators (ideally, individuals with relevant sales/marketing or competitive intelligence experience) review the evaluation packets.\n",
            "\n",
            "4.  **Conduct Evaluation:** For each packet, the evaluator should:\n",
            "    *   Read the user query and the retrieved competitor information to understand the context.\n",
            "    *   Read the generated counter-strategy.\n",
            "    *   Score the strategy based on each of the defined qualitative criteria (Relevance, Actionability, Clarity, Coherence, Support by Retrieval, Originality/Insight, Overall Quality) using the 1-5 scale.\n",
            "    *   Provide free-form comments detailing the strengths, weaknesses, and specific suggestions for improvement of the generated strategy.\n",
            "\n",
            "5.  **Aggregate and Analyze Results:** Collect all the evaluations. Aggregate the scores for each criterion across the sample. Analyze the comments to identify common themes, recurring issues, and specific areas where the strategies are strong or weak.\n",
            "\n",
            "6.  **Identify Areas for Refinement:** Based on the analysis, pinpoint specific aspects of the generated strategies that consistently score low or receive negative comments. This could relate to the strategy content itself, how well it uses the retrieved information, its practicality, etc.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e62069b"
      },
      "source": [
        "**Reasoning**:\n",
        "Describe how feedback from the evaluation would inform refinements to the RAG system and the LLM prompts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d20fbaf",
        "outputId": "12d698a3-80da-4b90-a17f-0d2bb26df725"
      },
      "source": [
        "# 3. Describe how feedback from the evaluation would inform refinements\n",
        "\n",
        "refinement_description = \"\"\"\n",
        "Using Evaluation Feedback for System Refinement:\n",
        "\n",
        "Feedback gathered from the manual evaluation process is crucial for iteratively improving the RAG system and LLM prompts. The insights from scores and comments will directly inform adjustments in the following ways:\n",
        "\n",
        "**Refining the RAG System:**\n",
        "\n",
        "*   **Relevance Scores & 'Support by Retrieval' Scores:** If strategies consistently score low on Relevance or Support by Retrieval, it indicates that the RAG system is not retrieving the most relevant information for the given queries.\n",
        "    *   **Action:** Analyze the retrieved chunks for low-scoring examples. Is the embedding model failing to capture semantic similarity effectively? Consider trying a different embedding model.\n",
        "    *   **Action:** Is the chunking strategy appropriate? Are chunks too large (diluting relevance) or too small (losing context)? Experiment with different chunk sizes and overlap values.\n",
        "    *   **Action:** Is the query formulation for retrieval optimal? Refine how the user query is processed before generating the embedding for retrieval.\n",
        "    *   **Action:** Are there issues with the data quality or coverage in the vector database? Identify gaps in the collected competitor data.\n",
        "\n",
        "*   **Originality/Insight Scores & Comments:** If strategies are merely summarizing retrieved content without adding value, it might suggest the RAG system is providing too much undigested information or the LLM isn't being prompted to synthesize effectively.\n",
        "    *   **Action:** Review the amount and diversity of retrieved chunks (`n_results`). Providing fewer, highly relevant chunks might help the LLM focus.\n",
        "\n",
        "**Refining the LLM Prompts:**\n",
        "\n",
        "*   **Actionability, Clarity, Coherence, Overall Quality Scores & Comments:** Low scores or negative comments on these criteria often point directly to issues with the LLM's output format, structure, or content generation style, which can be influenced by the prompt.\n",
        "    *   **Action:** Refine the `create_strategy_prompt` function. Make instructions clearer and more explicit.\n",
        "    *   **Action:** Experiment with different phrasing and examples in the prompt to guide the LLM towards more actionable, clear, and coherent outputs.\n",
        "    *   **Action:** Adjust the requested format (e.g., number of bullet points, paragraph length).\n",
        "    *   **Action:** Add more specific negative constraints (e.g., \"Do not use generic marketing buzzwords,\" \"Focus on competitive differentiation\").\n",
        "    *   **Action:** If using a more capable LLM, explore techniques like few-shot prompting by including examples of high-quality desired outputs in the prompt.\n",
        "\n",
        "*   **Consistency Across Evaluations:** If certain types of queries or retrieved information consistently lead to poor strategies, analyze those specific cases to understand if the prompt needs tailoring for different scenarios.\n",
        "\n",
        "**Iterative Process:**\n",
        "\n",
        "Refinement is an iterative process. After making changes based on evaluation feedback, generate a new sample of strategies, conduct another manual evaluation, and repeat the analysis and refinement steps until the desired quality level is achieved.\n",
        "\"\"\"\n",
        "\n",
        "print(\"How evaluation feedback informs refinements:\")\n",
        "print(refinement_description)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How evaluation feedback informs refinements:\n",
            "\n",
            "Using Evaluation Feedback for System Refinement:\n",
            "\n",
            "Feedback gathered from the manual evaluation process is crucial for iteratively improving the RAG system and LLM prompts. The insights from scores and comments will directly inform adjustments in the following ways:\n",
            "\n",
            "**Refining the RAG System:**\n",
            "\n",
            "*   **Relevance Scores & 'Support by Retrieval' Scores:** If strategies consistently score low on Relevance or Support by Retrieval, it indicates that the RAG system is not retrieving the most relevant information for the given queries.\n",
            "    *   **Action:** Analyze the retrieved chunks for low-scoring examples. Is the embedding model failing to capture semantic similarity effectively? Consider trying a different embedding model.\n",
            "    *   **Action:** Is the chunking strategy appropriate? Are chunks too large (diluting relevance) or too small (losing context)? Experiment with different chunk sizes and overlap values.\n",
            "    *   **Action:** Is the query formulation for retrieval optimal? Refine how the user query is processed before generating the embedding for retrieval.\n",
            "    *   **Action:** Are there issues with the data quality or coverage in the vector database? Identify gaps in the collected competitor data.\n",
            "\n",
            "*   **Originality/Insight Scores & Comments:** If strategies are merely summarizing retrieved content without adding value, it might suggest the RAG system is providing too much undigested information or the LLM isn't being prompted to synthesize effectively.\n",
            "    *   **Action:** Review the amount and diversity of retrieved chunks (`n_results`). Providing fewer, highly relevant chunks might help the LLM focus.\n",
            "\n",
            "**Refining the LLM Prompts:**\n",
            "\n",
            "*   **Actionability, Clarity, Coherence, Overall Quality Scores & Comments:** Low scores or negative comments on these criteria often point directly to issues with the LLM's output format, structure, or content generation style, which can be influenced by the prompt.\n",
            "    *   **Action:** Refine the `create_strategy_prompt` function. Make instructions clearer and more explicit.\n",
            "    *   **Action:** Experiment with different phrasing and examples in the prompt to guide the LLM towards more actionable, clear, and coherent outputs.\n",
            "    *   **Action:** Adjust the requested format (e.g., number of bullet points, paragraph length).\n",
            "    *   **Action:** Add more specific negative constraints (e.g., \"Do not use generic marketing buzzwords,\" \"Focus on competitive differentiation\").\n",
            "    *   **Action:** If using a more capable LLM, explore techniques like few-shot prompting by including examples of high-quality desired outputs in the prompt.\n",
            "\n",
            "*   **Consistency Across Evaluations:** If certain types of queries or retrieved information consistently lead to poor strategies, analyze those specific cases to understand if the prompt needs tailoring for different scenarios.\n",
            "\n",
            "**Iterative Process:**\n",
            "\n",
            "Refinement is an iterative process. After making changes based on evaluation feedback, generate a new sample of strategies, conduct another manual evaluation, and repeat the analysis and refinement steps until the desired quality level is achieved.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5458a695"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Required libraries for the project, including `transformers`, `torch`, `langchain`, `chromadb`, `beautifulsoup4`, `requests`, `streamlit`, and `gradio`, were successfully installed.\n",
        "*   A method for collecting competitor data was demonstrated by simulating data from various sources (blog, press release, product page) and storing it in a pandas DataFrame with columns for `source`, `title`, and `content`.\n",
        "*   A data preprocessing pipeline was implemented, including text cleaning (removing HTML, special characters, and excess whitespace) and text chunking based on sentence splitting with defined `max_chars` and `overlap`. The processed data was stored in a new DataFrame `df_chunks`.\n",
        "*   ChromaDB was set up as the vector database, and a persistent client and collection named `competitor_marketing_intelligence` were successfully initialized.\n",
        "*   An embedding model (`sentence-transformers/all-MiniLM-L6-v2`) and tokenizer were loaded using the `transformers` library.\n",
        "*   Embeddings were generated for the text chunks in `df_chunks` and stored in the ChromaDB collection along with metadata (source, title) and the text content stored correctly in the `documents` field after an initial correction.\n",
        "*   A RAG system was developed to retrieve relevant text chunks from the ChromaDB collection based on a user query by generating an embedding for the query and performing a similarity search.\n",
        "*   The mechanism for connecting the RAG output to an LLM input was implemented, including loading a small LLM (`distilgpt2`) and defining a function to format retrieved chunks and a user query into a prompt for generation.\n",
        "*   A detailed prompt template (`create_strategy_prompt`) was crafted to guide the LLM in generating actionable sales and marketing counter-strategies, including specific instructions on format, content, and constraints.\n",
        "*   A basic Gradio user interface was built with input for a user query and placeholder outputs for retrieved information and generated strategies, demonstrating the structure for user interaction.\n",
        "*   Qualitative criteria (relevance, actionability, clarity, coherence, support by retrieval, originality/insight, overall quality) for evaluating the generated strategies were defined.\n",
        "*   A detailed outline for a manual evaluation process was described, involving selecting samples, preparing evaluation packets, assigning evaluators, conducting evaluations based on criteria, and analyzing results.\n",
        "*   A clear explanation was provided on how feedback from the manual evaluation process would be used to refine both the RAG system (e.g., embedding model, chunking) and the LLM prompts (e.g., clarity, constraints).\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Replace placeholder logic in the Gradio interface with the actual RAG retrieval and LLM generation functions to create a functional end-to-end application.\n",
        "*   Integrate a more capable LLM (e.g., a larger model from Hugging Face or an external API like Gemini/OpenAI) and perform prompt engineering based on the defined evaluation criteria to improve the quality and actionability of generated strategies.\n"
      ]
    }
  ]
}